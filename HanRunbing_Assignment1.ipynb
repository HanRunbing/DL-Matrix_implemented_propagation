{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HanRunbing_Assignment1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oROwce1wowp"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWbOA_-L0B36",
        "outputId": "e695bbf8-e987-4bfa-e0f9-2d0de3a4bcfd"
      },
      "source": [
        "# randomly generate x,y\n",
        "x = np.random.rand(2)\n",
        "y = (x[0]**2 + x[1]**2)/2\n",
        "\n",
        "# first hidden layer\n",
        "w1 = np.random.rand(10,2)\n",
        "b1 = np.random.rand(10,1)\n",
        "\n",
        "# second hidden layer\n",
        "w2 = np.random.rand(10,10)\n",
        "b2 = np.random.rand(10,1)\n",
        "\n",
        "#output layer\n",
        "w3 = np.random.rand(1,10)\n",
        "b3 = np.random.rand(10)\n",
        "print(w3)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.78755917 0.08086249 0.67569912 0.75270991 0.1281115  0.51211049\n",
            "  0.2065043  0.04794155 0.01214613 0.24681122]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYOZXCoKZNfT"
      },
      "source": [
        "# Gradient calculation with script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcQW8e1j1zaf"
      },
      "source": [
        "def sigmoid(x):\n",
        "  # sigmoid function\n",
        "  return 1 / (1 + math. exp(-x))\n",
        "\n",
        "def forward(x,w,b,act,layer,torch_flag = False):\n",
        "  if layer == 1:\n",
        "    v1 = []\n",
        "    z = x * w + b\n",
        "    ze = 0\n",
        "    for i in range(10):\n",
        "      for j in range(2):\n",
        "        ze += z[i][j]\n",
        "        vv = act(ze)\n",
        "      v1.append(vv)\n",
        "    if torch_flag:\n",
        "      return v1,z\n",
        "    # the format of data type should be change when use pytorch\n",
        "    return np.array(v1),z \n",
        "  \n",
        "  # second layer pass\n",
        "  if layer == 2:\n",
        "    z = x * w + b\n",
        "    v2 = []\n",
        "    ze = 0\n",
        "    for i in range(10):\n",
        "      for j in range(10):\n",
        "        ze += z[i][j]\n",
        "      vv = act(ze)\n",
        "      v2.append(vv)\n",
        "    if torch_flag:\n",
        "      return v2,z\n",
        "    return np.array(v2),z \n",
        "    \n",
        "  # third layer pass\n",
        "  if layer == 3:\n",
        "    if torch_flag:\n",
        "        zz = 0\n",
        "        for i in range(10):\n",
        "          zz += x[i] * w[i] + b[i]\n",
        "        return zz\n",
        "    z = x * w + b\n",
        "    return np.sum(z)\n",
        "\n",
        "def loss(pred,y):\n",
        "  # loss function\n",
        "  L = (pred- y)**2\n",
        "  return L"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0yO5qwg22Cs"
      },
      "source": [
        "# dL/dw3 = 2(yred-y) * v2\n",
        "def gradient_w3(v,y,pred):\n",
        "  dw3 = []\n",
        "  for i in range(10):\n",
        "    dw = 2 *v[i]* (pred - y)\n",
        "    dw3.append(dw)\n",
        "  return np.array(dw3)\n",
        "\n",
        "# dL/db3 = 2(yred-y)\n",
        "def gradient_b3(y,pred):\n",
        "  db3 = []\n",
        "  for i in range(10):\n",
        "    db = 2 * (pred - y)\n",
        "    db3.append(db)\n",
        "  return np.array(db3)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdqDETUTN_wl"
      },
      "source": [
        "#dL/dw2 = 2(yred-y) * w3*sig(z2) * (1-sig(z2)) * v1\n",
        "def gradient_w2(v,y,pred,z2,w3):\n",
        "  dw2 = []\n",
        "  ze = 0\n",
        "  sigz2 = []\n",
        "  for i in range(10):\n",
        "    for j in range(10):\n",
        "        ze += z2[i][j]\n",
        "    sigz = sigmoid(ze) * (1 - sigmoid(ze))\n",
        "    # save the sig(z2), no need to calculate next time\n",
        "    sigz2.append(sigz)\n",
        "  sigz2 = np.array(sigz2)\n",
        "  dw = 2 * v * (pred - y) * sigz2 *w3.T\n",
        "  return dw,sigz2\n",
        "#dL/db2 = 2(yred-y) * w3*sig(z2) * (1-sig(z2))\n",
        "def gradient_b2(y,pred,sigz2,w3):\n",
        "  db = 2 * (pred - y)* sigz2  *w3\n",
        "  return db"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76FE9kUsQq_q"
      },
      "source": [
        "# dL/dw1 = 2 * (yred - y)* w3 *sig(z2) * w2 * sig(z1) * x\n",
        "def gradient_w1(x,y,w2,w3,z1,pred,sigz2):\n",
        "  dw1 = []\n",
        "  sigz1 = []\n",
        "  w2s = []\n",
        "  for i in range(10):\n",
        "    sigz = sigmoid(z1[i][0] + z1[i][1]) * (1 - sigmoid(z1[i][0] + z1[i][1]))\n",
        "    sigz1.append(sigz)\n",
        "    w2s.append(np.sum(w2[i]))\n",
        "\n",
        "  sigz1 = np.array(sigz1)\n",
        "  w2s = np.array(w2s)\n",
        "  dwtemp1 = 2 * x[0] * (pred - y) * w3 * sigz2 * w2s * sigz1\n",
        "  dwtemp2 = 2 * x[1] * (pred - y) * w3 * sigz2 * w2s * sigz1\n",
        "  dw1.append([dwtemp1,dwtemp2])\n",
        "  return np.array(dw1),sigz1\n",
        "\n",
        "# dL/db1 = 2 * (yred - y)* w3 *sig(z2) * w2 * sig(z1)\n",
        "def gradient_b1(y,pred,sigz2,sigz1,w2):\n",
        "  w2s = []\n",
        "  for i in range(10):\n",
        "    w2s.append(np.sum(w2[i]))\n",
        "  db = 2 * (pred - y) * w3 * sigz2  * w2s * sigz1\n",
        "  return db"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EABqcQUbN-El",
        "outputId": "7d92604b-d244-48ff-d601-e8e66eadb81a"
      },
      "source": [
        "# forward \n",
        "v1,z1 = forward(x,w1,b1,sigmoid,1)\n",
        "v2,z2 = forward(v1,w2,b2,sigmoid,2)\n",
        "y_pred = forward(v2,w3,b3,sigmoid,3)\n",
        "print('The predicted y is: '+ str(round(y_pred,2)))\n",
        "\n",
        "# loss\n",
        "L = loss(y_pred,y)\n",
        "\n",
        "# gradient decent\n",
        "dw3 = gradient_w3(v2,y,y_pred)\n",
        "db3 = gradient_b3(y,y_pred)\n",
        "dw2,sigz2 = gradient_w2(v1,y,y_pred,z2,w3)\n",
        "db2 = gradient_b2(y,y_pred,sigz2,w3)\n",
        "dw1, sigz1 = gradient_w1(x,y,w2,w3,z1,y_pred,sigz2)\n",
        "db1 = gradient_b1(y,y_pred,sigz2,sigz1,w2)\n",
        "\n",
        "\n",
        "print('-------------dw3------------')\n",
        "print(dw3)\n",
        "print('-------------db3------------')\n",
        "print(db3)\n",
        "print('-------------dw2------------')\n",
        "print(dw2)\n",
        "print('-------------db2------------')\n",
        "print(db2)\n",
        "print('-------------dw1------------')\n",
        "print(dw1)\n",
        "print('-------------db1------------')\n",
        "print(db1)\n",
        "\n",
        "# dw3 = dw3.flatten()\n",
        "# db3 = db3.flatten()\n",
        "# dw2 = dw2.flatten()\n",
        "# dw20 = dw2[:10]\n",
        "# dw21 = dw2[10:20]\n",
        "# dw22 = dw2[20:30]\n",
        "# dw23 = dw2[30:40]\n",
        "# dw24 = dw2[40:50]\n",
        "# dw25 = dw2[50:60]\n",
        "# dw26 = dw2[60:70]\n",
        "# dw27 = dw2[70:80]\n",
        "# dw28 = dw2[80:90]\n",
        "# dw29 = dw2[90:]\n",
        "# db2 = db2.flatten()\n",
        "# dw1 = dw1.flatten()\n",
        "# dw11 = dw1[:10]\n",
        "# dw12 = dw1[10:]\n",
        "# db1 = db1.flatten()\n",
        "\n",
        "# output_df = pd.DataFrame({'dw3': dw3,'db3':db3,'dw20': dw20,'dw21': dw21,'dw22': dw22,'dw23': dw23,'dw24': dw24,'dw25': dw25,\n",
        "#                           'dw26': dw26,'dw27': dw27,'dw28': dw28,'dw29': dw29,\n",
        "#                           'db2':db2,'dw11': dw11,'dw12':dw12,'db1':db1}) \n",
        "\n",
        "output_df = pd.DataFrame([{'dw3': dw3,'db3':db3,'dw2': dw2,'db2':db2,'dw1': dw1,'db1':db1}]) \n",
        "output_df.to_csv('gradient decent script.dat')"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted y is: 9.77\n",
            "-------------dw3------------\n",
            "[19.14415081 19.1878436  19.18784616 19.18784616 19.18784616 19.18784616\n",
            " 19.18784616 19.18784616 19.18784616 19.18784616]\n",
            "-------------db3------------\n",
            "[19.18784616 19.18784616 19.18784616 19.18784616 19.18784616 19.18784616\n",
            " 19.18784616 19.18784616 19.18784616 19.18784616]\n",
            "-------------dw2------------\n",
            "[[2.79266294e-02 1.91783311e-06 2.07400421e-09 6.68855428e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.86736144e-03 1.96913155e-07 2.12947994e-10 6.86746058e-15\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.39601031e-02 1.64543591e-06 1.77942544e-09 5.73855325e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.66908841e-02 1.83296954e-06 1.98223012e-09 6.39258768e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [4.54279817e-03 3.11972082e-07 3.37376287e-10 1.08802075e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.81592955e-02 1.24707130e-06 1.34862159e-09 4.34923356e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [7.32258499e-03 5.02871138e-07 5.43820448e-10 1.75379229e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [1.69999394e-03 1.16745369e-07 1.26252064e-10 4.07156253e-15\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [4.30698362e-04 2.95777756e-08 3.19863240e-11 1.03154209e-15\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [8.75185742e-03 6.01024981e-07 6.49967059e-10 2.09610951e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            "-------------db2------------\n",
            "[[3.43343076e-02 2.07232803e-07 1.81842883e-09 6.41392801e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n",
            "-------------dw1------------\n",
            "[[[[1.20624065e-02 8.10209465e-08 1.20579006e-09 1.20573483e-14\n",
            "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[5.91056959e-03 3.97001992e-08 5.90836167e-10 5.90809106e-15\n",
            "    0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]]]\n",
            "-------------db1------------\n",
            "[[2.23657795e-02 1.50226791e-07 2.23574247e-09 2.23564007e-14\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0TyTe60VHjC"
      },
      "source": [
        ""
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co1tP8E2nN7h"
      },
      "source": [
        "# Deap learning process with script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYsEm_xPj-og",
        "outputId": "f23e385b-433e-44e6-80c0-69b349fff31e"
      },
      "source": [
        "learning_rate = 0.01\n",
        "for epoch in range(10):\n",
        "  # forward \n",
        "  v1,z1 = forward(x,w1,b1,sigmoid,1)\n",
        "  v2,z2 = forward(v1,w2,b2,sigmoid,2)\n",
        "  y_pred = forward(v2,w3,b3,sigmoid,3)\n",
        "\n",
        "  # loss\n",
        "  L = loss(y_pred,y)\n",
        "\n",
        "  # gradient decent\n",
        "  dw3 = gradient_w3(v2,y,y_pred)\n",
        "  db3 = gradient_b3(y,y_pred)\n",
        "  dw2,sigz2 = gradient_w2(v1,y,y_pred,z2,w3)\n",
        "  db2 = gradient_b2(y,y_pred,sigz2,w3)\n",
        "  dw1, sigz1 = gradient_w1(x,y,w2,w3,z1,y_pred,sigz2)\n",
        "  db1 = gradient_b1(y,y_pred,sigz2,sigz1,w2)\n",
        "\n",
        "  # update w and b \n",
        "  w3 -= learning_rate * dw3\n",
        "  b3 -= learning_rate * db3\n",
        "  w2 -= learning_rate * dw2\n",
        "  b2 -= learning_rate * db2\n",
        "  w1 -= learning_rate * dw1\n",
        "  b1 -= learning_rate * db1\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f'epoch{epoch + 1}: loss = {L}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch1: loss = 142.64456701911698\n",
            "epoch2: loss = 51.3603192337142\n",
            "epoch3: loss = 18.492701088767955\n",
            "epoch4: loss = 6.658448327141117\n",
            "epoch5: loss = 2.397428867029006\n",
            "epoch6: loss = 0.8632139069983521\n",
            "epoch7: loss = 0.31080723920078707\n",
            "epoch8: loss = 0.11190869243280575\n",
            "epoch9: loss = 0.04029364129859838\n",
            "epoch10: loss = 0.014508055548621534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLQ790kHnkzb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SgqDqNVozMD"
      },
      "source": [
        "# Gradience calculation with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCZoy1dev7Fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fead663-51e8-4186-971b-3d6506d7b314"
      },
      "source": [
        "pip install torch"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0H0CiCvwa7C"
      },
      "source": [
        "def tforward(x,w,b,act,layer,torch_flag = False):\n",
        "  if layer == 1:\n",
        "    v1 = []\n",
        "    z = x * w + b\n",
        "    ze = 0\n",
        "    for i in range(10):\n",
        "      for j in range(2):\n",
        "        ze += z[i][j]\n",
        "        vv = act(ze)\n",
        "      v1.append(vv)\n",
        "    if torch_flag:\n",
        "      return v1,z\n",
        "    # the format of data type should be change when use pytorch\n",
        "    return np.array(v1),z \n",
        "  \n",
        "  # second layer pass\n",
        "  if layer == 2:\n",
        "    z = x * w + b\n",
        "    v2 = []\n",
        "    ze = 0\n",
        "    for i in range(10):\n",
        "      for j in range(10):\n",
        "        ze += z[i][j]\n",
        "      vv = act(ze)\n",
        "      v2.append(vv)\n",
        "    if torch_flag:\n",
        "      return v2,z\n",
        "    return np.array(v2),z \n",
        "    \n",
        "  # third layer pass\n",
        "  if layer == 3:\n",
        "    if torch_flag:\n",
        "        zz = 0\n",
        "        for i in range(10):\n",
        "          zz += x[i] * w[0][i] + b[i]\n",
        "        return zz\n",
        "    z = x * w + b\n",
        "    return np.sum(z)"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Au657bUBMXR",
        "outputId": "94640020-5a59-4519-b7ff-5cb55a15949c"
      },
      "source": [
        "# calculate gradient decent with torch\n",
        "import torch\n",
        "x_train = torch.tensor(x,requires_grad=True)\n",
        "y_train = torch.tensor(y,requires_grad=True)\n",
        "\n",
        "tw1 = torch.tensor(w1, requires_grad=True)\n",
        "tb1 = torch.tensor(b1, requires_grad=True)\n",
        "tw2 = torch.tensor(w2, requires_grad=True)\n",
        "tb2 = torch.tensor(b2, requires_grad=True)\n",
        "tw3 = torch.tensor(w3, requires_grad=True)\n",
        "tb3 = torch.tensor(b3, requires_grad=True)\n",
        "\n",
        "# active function\n",
        "m = torch.nn.Sigmoid()\n",
        "# forward \n",
        "v1,z = tforward(x_train,tw1,tb1,m,1,True)\n",
        "tv1 = torch.stack(v1)\n",
        "v2,z = tforward(tv1,tw2,tb2,m,2,True)\n",
        "tv2 = torch.stack(v2)\n",
        "tpred = tforward(tv2,tw3,tb3,m,3,True)\n",
        "\n",
        "# loss\n",
        "L = loss(tpred,y_train)\n",
        "# backward\n",
        "L.backward()\n",
        "\n",
        "print('The predicted y is:')\n",
        "print(tpred)\n",
        "print('-------------dw3------------')\n",
        "print(tw3.grad)\n",
        "print('-------------db3------------')\n",
        "print(tb3.grad)\n",
        "print('-------------dw2------------')\n",
        "print(tw2.grad)\n",
        "print('-------------db2------------')\n",
        "print(tb2.grad)\n",
        "print('-------------dw1------------')\n",
        "print(tw1.grad)\n",
        "print('-------------db1------------')\n",
        "print(tb1.grad)\n",
        "\n",
        "\n",
        "torch_df = pd.DataFrame([{'dw3': tw3.grad,'db3':tb3.grad,'dw2': tw2.grad,\n",
        "                         'db2':tb2.grad,'dw1': tw1.grad,'db1':tb1.grad}]) \n",
        "torch_df.to_csv('gradient decent torch.dat')\n"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted y is:\n",
            "tensor(9.7743, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "-------------dw3------------\n",
            "tensor([[19.1442, 19.1878, 19.1878, 19.1878, 19.1878, 19.1878, 19.1878, 19.1878,\n",
            "         19.1878, 19.1878]], dtype=torch.float64)\n",
            "-------------db3------------\n",
            "tensor([19.1878, 19.1878, 19.1878, 19.1878, 19.1878, 19.1878, 19.1878, 19.1878,\n",
            "        19.1878, 19.1878], dtype=torch.float64)\n",
            "-------------dw2------------\n",
            "tensor([[2.7927e-02, 3.2625e-02, 3.3598e-02, 3.4220e-02, 3.4292e-02, 3.4314e-02,\n",
            "         3.4331e-02, 3.4334e-02, 3.4334e-02, 3.4334e-02],\n",
            "        [1.7004e-07, 1.9864e-07, 2.0457e-07, 2.0836e-07, 2.0879e-07, 2.0892e-07,\n",
            "         2.0903e-07, 2.0905e-07, 2.0905e-07, 2.0905e-07],\n",
            "        [1.4791e-09, 1.7279e-09, 1.7795e-09, 1.8124e-09, 1.8163e-09, 1.8174e-09,\n",
            "         1.8183e-09, 1.8185e-09, 1.8185e-09, 1.8185e-09],\n",
            "        [5.2169e-14, 6.0945e-14, 6.2764e-14, 6.3926e-14, 6.4060e-14, 6.4100e-14,\n",
            "         6.4133e-14, 6.4138e-14, 6.4139e-14, 6.4139e-14],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], dtype=torch.float64)\n",
            "-------------db2------------\n",
            "tensor([[3.4335e-01],\n",
            "        [2.0905e-06],\n",
            "        [1.8185e-08],\n",
            "        [6.4139e-13],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00],\n",
            "        [0.0000e+00]], dtype=torch.float64)\n",
            "-------------dw1------------\n",
            "tensor([[4.5509e-04, 2.2299e-04],\n",
            "        [4.4848e-04, 2.1975e-04],\n",
            "        [2.0455e-04, 1.0023e-04],\n",
            "        [6.7848e-05, 3.3246e-05],\n",
            "        [2.2817e-05, 1.1180e-05],\n",
            "        [7.2079e-06, 3.5319e-06],\n",
            "        [1.6052e-06, 7.8653e-07],\n",
            "        [6.4650e-08, 3.1678e-08],\n",
            "        [2.4988e-08, 1.2244e-08],\n",
            "        [1.7056e-08, 8.3576e-09]], dtype=torch.float64)\n",
            "-------------db1------------\n",
            "tensor([[1.6876e-03],\n",
            "        [1.6631e-03],\n",
            "        [7.5855e-04],\n",
            "        [2.5161e-04],\n",
            "        [8.4612e-05],\n",
            "        [2.6729e-05],\n",
            "        [5.9525e-06],\n",
            "        [2.3974e-07],\n",
            "        [9.2664e-08],\n",
            "        [6.3251e-08]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlDkL4AmpEyq"
      },
      "source": [
        "# Deep learning process with pytorch"
      ]
    }
  ]
}